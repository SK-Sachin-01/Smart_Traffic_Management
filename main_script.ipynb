{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d9ecc1-910d-4851-87f6-03162f444272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db037db-baff-4d1d-85a2-bc1ba44a2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"runs/detect/best.pt\"\n",
    "\n",
    "model = YOLO(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27113227-5bcc-4023-b9dc-ca1607e9dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4de1d88-f9bb-41fa-a502-54cd4e069135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dill in c:\\users\\agarw\\appdata\\roaming\\python\\python312\\site-packages (0.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5a9dcf-d481-40e2-95f5-bd92baeca288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(input):\n",
    "    try:\n",
    "        # Try loading the input as an image\n",
    "        img = cv2.imread(input)\n",
    "        if img is not None:\n",
    "            return True  # Input is an image path\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return False  # Input is not an image path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade0f33a-e008-44cf-9827-e9034a7477b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bounding_box(img_path):\n",
    "    if not is_image(img_path):\n",
    "        image = img_path\n",
    "    else:\n",
    "        image = cv2.imread(img_path)\n",
    "    results = model(image)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    for result in results:\n",
    "        for box in result.boxes.xyxy:\n",
    "            x1, y1, x2, y2 = map(int, box[:4])  # Extract the coordinates\n",
    "            # print(f\"Box coordinates: ({x1}, {y1}), ({x2}, {y2})\" )\n",
    "            # Draw the bounding box and label on the image\n",
    "            cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            \n",
    "    \n",
    "    return image_rgb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8ba108-6b34-41e6-a4c8-33ca0f13cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 bus, 3 cars, 3 motorbikes, 1 pickup, 1 three wheelers -CNG-, 1 van, 1506.5ms\n",
      "Speed: 9.9ms preprocess, 1506.5ms inference, 4356.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[165, 156, 157],\n",
       "        [212, 203, 204],\n",
       "        [201, 195, 197],\n",
       "        ...,\n",
       "        [214, 209, 213],\n",
       "        [217, 212, 216],\n",
       "        [162, 157, 161]],\n",
       "\n",
       "       [[174, 165, 166],\n",
       "        [217, 208, 209],\n",
       "        [201, 195, 197],\n",
       "        ...,\n",
       "        [214, 209, 213],\n",
       "        [217, 212, 216],\n",
       "        [162, 157, 161]],\n",
       "\n",
       "       [[168, 159, 160],\n",
       "        [219, 210, 211],\n",
       "        [233, 224, 227],\n",
       "        ...,\n",
       "        [214, 209, 213],\n",
       "        [217, 212, 216],\n",
       "        [162, 157, 161]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 11,   2,  19],\n",
       "        [ 19,  10,  27],\n",
       "        [ 23,  14,  31],\n",
       "        ...,\n",
       "        [  7,   4,  21],\n",
       "        [  7,   4,  21],\n",
       "        [  7,   4,  21]],\n",
       "\n",
       "       [[ 11,   2,  19],\n",
       "        [ 19,  10,  27],\n",
       "        [ 23,  14,  31],\n",
       "        ...,\n",
       "        [  8,   5,  22],\n",
       "        [  7,   4,  21],\n",
       "        [  8,   5,  22]],\n",
       "\n",
       "       [[ 11,   2,  19],\n",
       "        [ 19,  10,  27],\n",
       "        [ 23,  14,  31],\n",
       "        ...,\n",
       "        [  9,   6,  23],\n",
       "        [  9,   6,  23],\n",
       "        [  9,   6,  23]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = \"valid/images/Pias--140-_jpg.rf.1fa359c696f211a5fe03f52d0d7c004a.jpg\"\n",
    "make_bounding_box(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2026f363-6919-4b1c-a8fd-6e342a865852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "def count_classes_in_image(image_path):\n",
    "    \n",
    "\n",
    "    # Load the image\n",
    "    if not is_image(image_path):\n",
    "        image = image_path\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(image)\n",
    "\n",
    "\n",
    "    # Extract class IDs\n",
    "    class_ids = []\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            class_id = int(box[-1].item())  # Assuming the class ID is the last element\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "    # Count the number of instances of each class\n",
    "    class_counts = Counter(class_ids)\n",
    "\n",
    "    # Map class IDs to class names\n",
    "    class_names = {cls_id: model.names[cls_id] for cls_id in class_counts.keys()}\n",
    "    class_counts_named = {class_names[cls_id]: count for cls_id, count in class_counts.items()}\n",
    "\n",
    "    return class_counts_named\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae5e215-fbb3-44d7-a756-3118cc2a0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 bus, 3 cars, 3 motorbikes, 1 pickup, 1 three wheelers -CNG-, 1 van, 1658.5ms\n",
      "Speed: 5.0ms preprocess, 1658.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pickup': 1,\n",
       " 'motorbike': 3,\n",
       " 'three wheelers -CNG-': 1,\n",
       " 'car': 3,\n",
       " 'bus': 1,\n",
       " 'van': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_classes_in_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52056773-f9bc-4d6e-84e2-d0047893f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 bus, 3 cars, 3 motorbikes, 1 pickup, 1 three wheelers -CNG-, 1 van, 1621.0ms\n",
      "Speed: 6.1ms preprocess, 1621.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'ambulance', 1: 'army vehicle', 2: 'auto rickshaw', 3: 'bicycle', 4: 'bus', 5: 'car', 6: 'garbagevan', 7: 'human hauler', 8: 'minibus', 9: 'minivan', 10: 'motorbike', 11: 'pickup', 12: 'policecar', 13: 'rickshaw', 14: 'scooter', 15: 'suv', 16: 'taxi', 17: 'three wheelers -CNG-', 18: 'truck', 19: 'van', 20: 'wheelbarrow'}\n",
      "obb: None\n",
      "orig_img: array([[[157, 156, 165],\n",
      "        [204, 203, 212],\n",
      "        [197, 195, 201],\n",
      "        ...,\n",
      "        [213, 209, 214],\n",
      "        [216, 212, 217],\n",
      "        [161, 157, 162]],\n",
      "\n",
      "       [[166, 165, 174],\n",
      "        [209, 208, 217],\n",
      "        [197, 195, 201],\n",
      "        ...,\n",
      "        [213, 209, 214],\n",
      "        [216, 212, 217],\n",
      "        [161, 157, 162]],\n",
      "\n",
      "       [[160, 159, 168],\n",
      "        [211, 210, 219],\n",
      "        [227, 224, 233],\n",
      "        ...,\n",
      "        [213, 209, 214],\n",
      "        [216, 212, 217],\n",
      "        [161, 157, 162]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 19,   2,  11],\n",
      "        [ 27,  10,  19],\n",
      "        [ 31,  14,  23],\n",
      "        ...,\n",
      "        [ 21,   4,   7],\n",
      "        [ 21,   4,   7],\n",
      "        [ 21,   4,   7]],\n",
      "\n",
      "       [[ 19,   2,  11],\n",
      "        [ 27,  10,  19],\n",
      "        [ 31,  14,  23],\n",
      "        ...,\n",
      "        [ 22,   5,   8],\n",
      "        [ 21,   4,   7],\n",
      "        [ 22,   5,   8]],\n",
      "\n",
      "       [[ 19,   2,  11],\n",
      "        [ 27,  10,  19],\n",
      "        [ 31,  14,  23],\n",
      "        ...,\n",
      "        [ 23,   6,   9],\n",
      "        [ 23,   6,   9],\n",
      "        [ 23,   6,   9]]], dtype=uint8)\n",
      "orig_shape: (359, 640)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 6.096363067626953, 'inference': 1621.009349822998, 'postprocess': 2.9087066650390625}\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([11.])\n",
      "conf: tensor([0.8722])\n",
      "data: tensor([[262.4976, 200.7070, 306.2368, 232.0275,   0.8722,  11.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[284.3672, 216.3672,  43.7393,  31.3206]])\n",
      "xywhn: tensor([[0.4443, 0.6027, 0.0683, 0.0872]])\n",
      "xyxy: tensor([[262.4976, 200.7070, 306.2368, 232.0275]])\n",
      "xyxyn: tensor([[0.4102, 0.5591, 0.4785, 0.6463]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([10.])\n",
      "conf: tensor([0.8714])\n",
      "data: tensor([[347.2734, 260.6976, 407.9243, 353.7950,   0.8714,  10.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[377.5988, 307.2463,  60.6509,  93.0974]])\n",
      "xywhn: tensor([[0.5900, 0.8558, 0.0948, 0.2593]])\n",
      "xyxy: tensor([[347.2734, 260.6976, 407.9243, 353.7950]])\n",
      "xyxyn: tensor([[0.5426, 0.7262, 0.6374, 0.9855]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([17.])\n",
      "conf: tensor([0.8589])\n",
      "data: tensor([[508.5371, 205.7246, 640.0000, 351.2846,   0.8589,  17.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[574.2686, 278.5046, 131.4629, 145.5600]])\n",
      "xywhn: tensor([[0.8973, 0.7758, 0.2054, 0.4055]])\n",
      "xyxy: tensor([[508.5371, 205.7246, 640.0000, 351.2846]])\n",
      "xyxyn: tensor([[0.7946, 0.5730, 1.0000, 0.9785]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.8405])\n",
      "data: tensor([[388.9119, 226.5316, 427.7837, 271.2834,   0.8405,   5.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[408.3478, 248.9075,  38.8718,  44.7518]])\n",
      "xywhn: tensor([[0.6380, 0.6933, 0.0607, 0.1247]])\n",
      "xyxy: tensor([[388.9119, 226.5316, 427.7837, 271.2834]])\n",
      "xyxyn: tensor([[0.6077, 0.6310, 0.6684, 0.7557]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([10.])\n",
      "conf: tensor([0.7477])\n",
      "data: tensor([[438.5599, 227.1571, 456.0605, 254.9465,   0.7477,  10.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[447.3102, 241.0518,  17.5005,  27.7894]])\n",
      "xywhn: tensor([[0.6989, 0.6715, 0.0273, 0.0774]])\n",
      "xyxy: tensor([[438.5599, 227.1571, 456.0605, 254.9465]])\n",
      "xyxyn: tensor([[0.6852, 0.6327, 0.7126, 0.7102]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([4.])\n",
      "conf: tensor([0.7280])\n",
      "data: tensor([[469.5369, 197.9696, 502.7021, 225.4655,   0.7280,   4.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[486.1195, 211.7176,  33.1653,  27.4958]])\n",
      "xywhn: tensor([[0.7596, 0.5897, 0.0518, 0.0766]])\n",
      "xyxy: tensor([[469.5369, 197.9696, 502.7021, 225.4655]])\n",
      "xyxyn: tensor([[0.7337, 0.5514, 0.7855, 0.6280]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.5854])\n",
      "data: tensor([[416.6011, 217.5599, 431.7057, 235.4580,   0.5854,   5.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[424.1534, 226.5089,  15.1046,  17.8981]])\n",
      "xywhn: tensor([[0.6627, 0.6309, 0.0236, 0.0499]])\n",
      "xyxy: tensor([[416.6011, 217.5599, 431.7057, 235.4580]])\n",
      "xyxyn: tensor([[0.6509, 0.6060, 0.6745, 0.6559]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.4378])\n",
      "data: tensor([[318.0085, 215.9498, 336.2147, 227.5805,   0.4378,   5.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[327.1116, 221.7651,  18.2061,  11.6307]])\n",
      "xywhn: tensor([[0.5111, 0.6177, 0.0284, 0.0324]])\n",
      "xyxy: tensor([[318.0085, 215.9498, 336.2147, 227.5805]])\n",
      "xyxyn: tensor([[0.4969, 0.6015, 0.5253, 0.6339]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([19.])\n",
      "conf: tensor([0.3488])\n",
      "data: tensor([[4.6979e+02, 1.9781e+02, 5.0295e+02, 2.2522e+02, 3.4878e-01, 1.9000e+01]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[486.3719, 211.5135,  33.1615,  27.4030]])\n",
      "xywhn: tensor([[0.7600, 0.5892, 0.0518, 0.0763]])\n",
      "xyxy: tensor([[469.7912, 197.8120, 502.9527, 225.2150]])\n",
      "xyxyn: tensor([[0.7340, 0.5510, 0.7859, 0.6273]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([10.])\n",
      "conf: tensor([0.3163])\n",
      "data: tensor([[193.2785, 222.7690, 213.7419, 241.8631,   0.3163,  10.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (359, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[203.5102, 232.3160,  20.4634,  19.0941]])\n",
      "xywhn: tensor([[0.3180, 0.6471, 0.0320, 0.0532]])\n",
      "xyxy: tensor([[193.2785, 222.7690, 213.7419, 241.8631]])\n",
      "xyxyn: tensor([[0.3020, 0.6205, 0.3340, 0.6737]])\n"
     ]
    }
   ],
   "source": [
    "image_path = 'valid/images/Pias--140-_jpg.rf.1fa359c696f211a5fe03f52d0d7c004a.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    for box in result.boxes:\n",
    "        print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0bc051f-b01e-4527-8906-48706210cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "        'ambulance': 5, 'army vehicle': 5, 'auto rickshaw': 2, 'bicycle': 1,\n",
    "        'bus': 10, 'car': 3, 'garbagevan': 7, 'human hauler': 6, 'minibus': 8,\n",
    "        'minivan': 4, 'motorbike': 1, 'pickup': 4, 'policecar': 5, 'rickshaw': 2,\n",
    "        'scooter': 1, 'suv': 4, 'taxi': 3, 'three wheelers -CNG-': 3, 'truck': 9,\n",
    "        'van': 4, 'wheelbarrow': 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72e8950a-8861-44fc-b8c7-c6eacc9c822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(img):\n",
    "    class_count=count_classes_in_image(img)\n",
    "    weighted_traffic=0\n",
    "    for cls_id, count in class_count.items():\n",
    "        class_name = cls_id\n",
    "        weight = weights.get(class_name, 1)  # Default weight is 1 if not specified\n",
    "        weighted_traffic += (count * weight)\n",
    "        \n",
    "    return weighted_traffic\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f657040a-077d-449d-b6e8-0367afd31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 bus, 3 cars, 3 motorbikes, 1 pickup, 1 three wheelers -CNG-, 1 van, 1587.8ms\n",
      "Speed: 6.0ms preprocess, 1587.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_weight(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fe30617-526e-4aad-b916-876b291fa356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_video_frames(video_path):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():    # check whether its opened or not \n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:     # frame detection ck\n",
    "            break\n",
    "        cv2.namedWindow('Video Frame', cv2.WINDOW_NORMAL)  # Create window with resizable option\n",
    "\n",
    "        img = make_bounding_box(frame)\n",
    "        weight= calculate_weight(frame)\n",
    "        print(weight)\n",
    "        # Display the frame\n",
    "        cv2.imshow('original',frame)\n",
    "        cv2.imshow('Video Frame', img)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92d4f3b3-d2bf-4619-b7ed-32429cc89ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 1 suv, 1557.8ms\n",
      "Speed: 11.9ms preprocess, 1557.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 suv, 1623.8ms\n",
      "Speed: 7.0ms preprocess, 1623.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 5 cars, 1 suv, 1487.6ms\n",
      "Speed: 6.0ms preprocess, 1487.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 suv, 911.0ms\n",
      "Speed: 5.0ms preprocess, 911.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 263.6ms\n",
      "Speed: 4.0ms preprocess, 263.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 250.6ms\n",
      "Speed: 2.0ms preprocess, 250.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "16\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 271.6ms\n",
      "Speed: 3.0ms preprocess, 271.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 260.0ms\n",
      "Speed: 2.0ms preprocess, 260.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "16\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 264.1ms\n",
      "Speed: 3.0ms preprocess, 264.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 258.6ms\n",
      "Speed: 2.0ms preprocess, 258.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 263.6ms\n",
      "Speed: 3.0ms preprocess, 263.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 291.6ms\n",
      "Speed: 3.0ms preprocess, 291.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 248.6ms\n",
      "Speed: 4.0ms preprocess, 248.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 277.6ms\n",
      "Speed: 3.0ms preprocess, 277.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 253.0ms\n",
      "Speed: 3.0ms preprocess, 253.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 262.0ms\n",
      "Speed: 3.0ms preprocess, 262.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 279.6ms\n",
      "Speed: 3.0ms preprocess, 279.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 272.6ms\n",
      "Speed: 2.0ms preprocess, 272.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 284.5ms\n",
      "Speed: 2.0ms preprocess, 284.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 258.6ms\n",
      "Speed: 2.0ms preprocess, 258.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 274.6ms\n",
      "Speed: 2.0ms preprocess, 274.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 261.6ms\n",
      "Speed: 4.0ms preprocess, 261.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 279.6ms\n",
      "Speed: 4.0ms preprocess, 279.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 234.0ms\n",
      "Speed: 2.0ms preprocess, 234.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 280.6ms\n",
      "Speed: 3.0ms preprocess, 280.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 266.6ms\n",
      "Speed: 4.0ms preprocess, 266.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 5 cars, 1 minivan, 2 suvs, 244.6ms\n",
      "Speed: 3.0ms preprocess, 244.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 minivan, 2 suvs, 262.0ms\n",
      "Speed: 4.0ms preprocess, 262.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 254.0ms\n",
      "Speed: 4.0ms preprocess, 254.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 287.5ms\n",
      "Speed: 3.0ms preprocess, 287.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 5 cars, 1 minivan, 1 suv, 240.6ms\n",
      "Speed: 3.0ms preprocess, 240.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 minivan, 1 suv, 265.6ms\n",
      "Speed: 4.0ms preprocess, 265.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 5 cars, 3 suvs, 241.0ms\n",
      "Speed: 3.0ms preprocess, 241.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 3 suvs, 263.6ms\n",
      "Speed: 3.0ms preprocess, 263.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 5 cars, 3 suvs, 260.6ms\n",
      "Speed: 2.0ms preprocess, 260.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 3 suvs, 325.6ms\n",
      "Speed: 3.0ms preprocess, 325.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 258.0ms\n",
      "Speed: 2.0ms preprocess, 258.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 267.6ms\n",
      "Speed: 3.0ms preprocess, 267.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 5 cars, 1 suv, 256.6ms\n",
      "Speed: 2.0ms preprocess, 256.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 suv, 264.0ms\n",
      "Speed: 1.0ms preprocess, 264.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 262.0ms\n",
      "Speed: 2.0ms preprocess, 262.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 270.6ms\n",
      "Speed: 3.0ms preprocess, 270.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 243.6ms\n",
      "Speed: 4.0ms preprocess, 243.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 270.6ms\n",
      "Speed: 3.0ms preprocess, 270.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 252.0ms\n",
      "Speed: 3.0ms preprocess, 252.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 244.0ms\n",
      "Speed: 2.0ms preprocess, 244.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 268.6ms\n",
      "Speed: 4.0ms preprocess, 268.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 273.6ms\n",
      "Speed: 2.0ms preprocess, 273.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 2 suvs, 239.0ms\n",
      "Speed: 3.0ms preprocess, 239.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 2 suvs, 245.6ms\n",
      "Speed: 2.0ms preprocess, 245.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 1 suv, 261.5ms\n",
      "Speed: 4.0ms preprocess, 261.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 1 suv, 247.0ms\n",
      "Speed: 4.0ms preprocess, 247.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 3 suvs, 260.0ms\n",
      "Speed: 3.0ms preprocess, 260.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 3 suvs, 316.1ms\n",
      "Speed: 2.0ms preprocess, 316.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "28\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 3 suvs, 272.6ms\n",
      "Speed: 3.0ms preprocess, 272.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 pickup, 3 suvs, 269.1ms\n",
      "Speed: 3.0ms preprocess, 269.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "31\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 244.0ms\n",
      "Speed: 3.0ms preprocess, 244.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 230.0ms\n",
      "Speed: 2.0ms preprocess, 230.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 256.0ms\n",
      "Speed: 4.0ms preprocess, 256.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 273.6ms\n",
      "Speed: 3.0ms preprocess, 273.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 2 suvs, 290.1ms\n",
      "Speed: 3.0ms preprocess, 290.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 2 suvs, 299.1ms\n",
      "Speed: 3.0ms preprocess, 299.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "24\n",
      "\n",
      "0: 384x640 3 cars, 1 pickup, 2 suvs, 307.6ms\n",
      "Speed: 5.0ms preprocess, 307.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 pickup, 2 suvs, 261.0ms\n",
      "Speed: 3.0ms preprocess, 261.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 2 suvs, 289.6ms\n",
      "Speed: 4.0ms preprocess, 289.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 pickup, 2 suvs, 277.7ms\n",
      "Speed: 3.0ms preprocess, 277.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "24\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 298.6ms\n",
      "Speed: 4.0ms preprocess, 298.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 263.0ms\n",
      "Speed: 2.0ms preprocess, 263.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "14\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 272.6ms\n",
      "Speed: 2.0ms preprocess, 272.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 suvs, 276.7ms\n",
      "Speed: 4.0ms preprocess, 276.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 264.1ms\n",
      "Speed: 3.0ms preprocess, 264.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suv, 271.6ms\n",
      "Speed: 3.0ms preprocess, 271.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "16\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 253.5ms\n",
      "Speed: 3.0ms preprocess, 253.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 254.6ms\n",
      "Speed: 2.0ms preprocess, 254.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 300.6ms\n",
      "Speed: 2.0ms preprocess, 300.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 292.5ms\n",
      "Speed: 4.0ms preprocess, 292.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 283.6ms\n",
      "Speed: 4.0ms preprocess, 283.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 304.6ms\n",
      "Speed: 2.0ms preprocess, 304.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 287.5ms\n",
      "Speed: 2.0ms preprocess, 287.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 290.6ms\n",
      "Speed: 3.0ms preprocess, 290.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "14\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 282.6ms\n",
      "Speed: 3.0ms preprocess, 282.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 372.1ms\n",
      "Speed: 4.0ms preprocess, 372.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "14\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 1 van, 261.6ms\n",
      "Speed: 2.0ms preprocess, 261.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 1 van, 340.1ms\n",
      "Speed: 3.0ms preprocess, 340.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 315.6ms\n",
      "Speed: 4.0ms preprocess, 315.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 414.1ms\n",
      "Speed: 4.0ms preprocess, 414.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 340.6ms\n",
      "Speed: 2.0ms preprocess, 340.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 340.1ms\n",
      "Speed: 2.0ms preprocess, 340.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 328.6ms\n",
      "Speed: 2.0ms preprocess, 328.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 305.6ms\n",
      "Speed: 2.0ms preprocess, 305.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 1 van, 274.6ms\n",
      "Speed: 3.0ms preprocess, 274.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 1 van, 284.6ms\n",
      "Speed: 2.0ms preprocess, 284.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 2 vans, 308.5ms\n",
      "Speed: 4.0ms preprocess, 308.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 2 vans, 311.6ms\n",
      "Speed: 3.0ms preprocess, 311.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "29\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 2 vans, 285.5ms\n",
      "Speed: 3.0ms preprocess, 285.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 2 vans, 300.6ms\n",
      "Speed: 3.0ms preprocess, 300.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "29\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 2 vans, 281.6ms\n",
      "Speed: 2.0ms preprocess, 281.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 2 vans, 297.2ms\n",
      "Speed: 3.0ms preprocess, 297.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 1 van, 294.6ms\n",
      "Speed: 3.0ms preprocess, 294.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 suvs, 1 van, 317.0ms\n",
      "Speed: 2.5ms preprocess, 317.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 1 van, 321.0ms\n",
      "Speed: 3.0ms preprocess, 321.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 1 van, 287.6ms\n",
      "Speed: 4.0ms preprocess, 287.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 287.6ms\n",
      "Speed: 2.0ms preprocess, 287.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 289.6ms\n",
      "Speed: 3.0ms preprocess, 289.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 292.6ms\n",
      "Speed: 3.0ms preprocess, 292.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 292.3ms\n",
      "Speed: 3.0ms preprocess, 292.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 318.6ms\n",
      "Speed: 4.0ms preprocess, 318.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 242.6ms\n",
      "Speed: 2.0ms preprocess, 242.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 255.1ms\n",
      "Speed: 3.0ms preprocess, 255.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 315.6ms\n",
      "Speed: 3.5ms preprocess, 315.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 3 suvs, 271.1ms\n",
      "Speed: 4.0ms preprocess, 271.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 3 suvs, 269.0ms\n",
      "Speed: 3.0ms preprocess, 269.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 3 suvs, 1039.4ms\n",
      "Speed: 2.0ms preprocess, 1039.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 3 suvs, 1569.7ms\n",
      "Speed: 6.0ms preprocess, 1569.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 2 suvs, 1 van, 1654.2ms\n",
      "Speed: 5.0ms preprocess, 1654.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 motorbike, 2 suvs, 1 van, 273.0ms\n",
      "Speed: 3.0ms preprocess, 273.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 3 cars, 1 motorbike, 3 suvs, 1 van, 312.2ms\n",
      "Speed: 2.0ms preprocess, 312.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 motorbike, 3 suvs, 1 van, 269.6ms\n",
      "Speed: 2.0ms preprocess, 269.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "26\n",
      "\n",
      "0: 384x640 3 cars, 1 motorbike, 2 suvs, 1 three wheelers -CNG-, 293.6ms\n",
      "Speed: 3.0ms preprocess, 293.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 motorbike, 2 suvs, 1 three wheelers -CNG-, 258.1ms\n",
      "Speed: 2.0ms preprocess, 258.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 1 three wheelers -CNG-, 287.6ms\n",
      "Speed: 4.0ms preprocess, 287.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 1 three wheelers -CNG-, 277.6ms\n",
      "Speed: 2.0ms preprocess, 277.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 1 three wheelers -CNG-, 286.5ms\n",
      "Speed: 4.0ms preprocess, 286.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 1 three wheelers -CNG-, 300.6ms\n",
      "Speed: 3.0ms preprocess, 300.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 270.6ms\n",
      "Speed: 3.0ms preprocess, 270.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 276.6ms\n",
      "Speed: 3.0ms preprocess, 276.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 293.5ms\n",
      "Speed: 3.0ms preprocess, 293.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 282.6ms\n",
      "Speed: 2.0ms preprocess, 282.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 281.6ms\n",
      "Speed: 2.0ms preprocess, 281.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 2 suvs, 299.6ms\n",
      "Speed: 2.0ms preprocess, 299.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 286.6ms\n",
      "Speed: 3.0ms preprocess, 286.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 271.6ms\n",
      "Speed: 3.0ms preprocess, 271.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "24\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 309.6ms\n",
      "Speed: 2.0ms preprocess, 309.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 275.6ms\n",
      "Speed: 4.0ms preprocess, 275.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 285.6ms\n",
      "Speed: 4.0ms preprocess, 285.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 274.6ms\n",
      "Speed: 3.0ms preprocess, 274.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "22\n",
      "\n",
      "0: 384x640 2 cars, 1 minivan, 4 suvs, 300.8ms\n",
      "Speed: 4.0ms preprocess, 300.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 minivan, 4 suvs, 302.6ms\n",
      "Speed: 3.0ms preprocess, 302.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "26\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 4 suvs, 318.1ms\n",
      "Speed: 3.0ms preprocess, 318.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 4 suvs, 276.0ms\n",
      "Speed: 3.0ms preprocess, 276.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "29\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 298.2ms\n",
      "Speed: 4.0ms preprocess, 298.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 3 suvs, 265.7ms\n",
      "Speed: 4.0ms preprocess, 265.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 4 suvs, 270.1ms\n",
      "Speed: 2.0ms preprocess, 270.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 4 suvs, 261.5ms\n",
      "Speed: 3.0ms preprocess, 261.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "29\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 278.6ms\n",
      "Speed: 3.0ms preprocess, 278.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 261.6ms\n",
      "Speed: 3.0ms preprocess, 261.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "22\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 247.6ms\n",
      "Speed: 3.0ms preprocess, 247.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 4 suvs, 263.0ms\n",
      "Speed: 2.0ms preprocess, 263.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "22\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 256.0ms\n",
      "Speed: 2.0ms preprocess, 256.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 288.6ms\n",
      "Speed: 3.0ms preprocess, 288.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 290.6ms\n",
      "Speed: 4.0ms preprocess, 290.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 269.6ms\n",
      "Speed: 3.0ms preprocess, 269.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 270.6ms\n",
      "Speed: 2.0ms preprocess, 270.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 288.4ms\n",
      "Speed: 3.0ms preprocess, 288.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 256.6ms\n",
      "Speed: 2.0ms preprocess, 256.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 289.6ms\n",
      "Speed: 2.0ms preprocess, 289.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 284.5ms\n",
      "Speed: 3.0ms preprocess, 284.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 248.0ms\n",
      "Speed: 3.0ms preprocess, 248.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 240.0ms\n",
      "Speed: 2.5ms preprocess, 240.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 1709.9ms\n",
      "Speed: 2.0ms preprocess, 1709.9ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 1794.7ms\n",
      "Speed: 33.0ms preprocess, 1794.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 1923.5ms\n",
      "Speed: 7.9ms preprocess, 1923.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 1611.2ms\n",
      "Speed: 9.0ms preprocess, 1611.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 4 suvs, 530.2ms\n",
      "Speed: 5.0ms preprocess, 530.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 349.4ms\n",
      "Speed: 4.0ms preprocess, 349.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 3 suvs, 333.6ms\n",
      "Speed: 3.0ms preprocess, 333.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "24\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 317.7ms\n",
      "Speed: 3.8ms preprocess, 317.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 351.2ms\n",
      "Speed: 3.0ms preprocess, 351.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 295.8ms\n",
      "Speed: 2.0ms preprocess, 295.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 337.8ms\n",
      "Speed: 4.0ms preprocess, 337.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 304.0ms\n",
      "Speed: 3.0ms preprocess, 304.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 297.0ms\n",
      "Speed: 4.0ms preprocess, 297.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 4 cars, 1 minivan, 4 suvs, 318.6ms\n",
      "Speed: 2.0ms preprocess, 318.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 minivan, 4 suvs, 339.8ms\n",
      "Speed: 3.0ms preprocess, 339.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "32\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 326.0ms\n",
      "Speed: 4.0ms preprocess, 326.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 276.5ms\n",
      "Speed: 3.0ms preprocess, 276.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 273.5ms\n",
      "Speed: 3.0ms preprocess, 273.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 3 suvs, 302.1ms\n",
      "Speed: 2.5ms preprocess, 302.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 307.4ms\n",
      "Speed: 3.0ms preprocess, 307.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 3 suvs, 334.9ms\n",
      "Speed: 4.0ms preprocess, 334.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 311.6ms\n",
      "Speed: 3.0ms preprocess, 311.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 305.6ms\n",
      "Speed: 3.0ms preprocess, 305.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 4 cars, 1 minivan, 1 suv, 333.9ms\n",
      "Speed: 3.0ms preprocess, 333.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 minivan, 1 suv, 318.0ms\n",
      "Speed: 3.0ms preprocess, 318.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 308.4ms\n",
      "Speed: 2.0ms preprocess, 308.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 237.2ms\n",
      "Speed: 3.0ms preprocess, 237.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 246.8ms\n",
      "Speed: 1.0ms preprocess, 246.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 1 suv, 357.5ms\n",
      "Speed: 4.0ms preprocess, 357.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 1 van, 579.8ms\n",
      "Speed: 6.0ms preprocess, 579.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 minivan, 2 suvs, 1 van, 1751.5ms\n",
      "Speed: 7.0ms preprocess, 1751.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 1733.2ms\n",
      "Speed: 14.1ms preprocess, 1733.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 5125.6ms\n",
      "Speed: 4.7ms preprocess, 5125.6ms inference, 62.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 1 bus, 3 cars, 2 suvs, 3235.5ms\n",
      "Speed: 13.5ms preprocess, 3235.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 3 cars, 2 suvs, 3036.9ms\n",
      "Speed: 8.5ms preprocess, 3036.9ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 1 van, 2651.8ms\n",
      "Speed: 17.1ms preprocess, 2651.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 suvs, 1 van, 2774.5ms\n",
      "Speed: 13.0ms preprocess, 2774.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1 van, 1525.6ms\n",
      "Speed: 5.9ms preprocess, 1525.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1 van, 1508.6ms\n",
      "Speed: 5.1ms preprocess, 1508.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1549.7ms\n",
      "Speed: 5.0ms preprocess, 1549.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1405.8ms\n",
      "Speed: 6.1ms preprocess, 1405.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "13\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1423.5ms\n",
      "Speed: 5.1ms preprocess, 1423.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 suv, 1556.5ms\n",
      "Speed: 6.0ms preprocess, 1556.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video = \"video/8321868-hd_1920_1080_30fps.mp4\"\n",
    "process_video_frames(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473084c0-dd02-4bf9-a2dd-1d52e2e2b280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_env",
   "language": "python",
   "name": "traffic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
